The problem under consideration is the ability of a machine learning algorithm to predict costs associated with a natural disaster. The opportunity arises from the FEMA mission assignment database that documents States' requests for reimbursable assistance from the federal government during an emergency. I hope to determine if there are detectable patterns in the data related to the cost of events. I expect the project to take three weeks, consisting of data preparation, training and testing, and analysis phases for each machine learning algorithm: linear regression, ARIMA, and a Recurrent Neural Network.

A search of Google Scholar using the terms FEMA "Mission Assignment" Dataset "machine learning" returns seven results, three of which have full text available. Three of the results are books, and one is a PDF document. Rapid damage assessment using social media images by combining human and machine intelligence (Imran et al., 2020) deals with using AI/human pairing to monitor social media posts to assess damage during a disaster. FEMA is identified as a stakeholder in such disasters. Ai for disaster rapid damage assessment from microblogs (Imran et al., 2022) It also uses AI/human pairing to monitor social media posts and assess damage during a disaster. FEMA is identified as a stakeholder in such disasters. Cooperative multiple agent-based algorithm for evacuation planning for victims with different urgencies (Oh et al., 2018) addresses using a multi-agent AI system to help plan evacuation routes by allowing independent agents to coordinate their strategy. Cyber Mutual Assistance Workshop Report (Monken et al., 2018) describes the results of a power sector cyberattack and perspective mitigation and recovery options. FEMA has been identified as having a significant role in managing the effects of such an attack. Engaging the private-sector health care system in building capacity to respond to threats to the public's health and national security: Proceedings of a workshop (Alper, 2018) talks about FEMA’s role in the National Response Framework. Development of Autonomous Robotic Ground Vehicles: DoD’s Ground Robotics Research Programs: Demo I through Demo III (Shoemaker, 2006) talks about FEMA’s role in the US Army’s development of robotic ground vehicles. The new era in US national security: challenges of the information age (Jarmon, 2019) talks briefly about FEMA’s role in national security.

None of the identified works address the use of FEMA’s data to predict aspects of future events. This work will explore ways in which FEMA’s data can be useful for disaster planning and management. During the first week of work, I conducted data exploration, preparation, and analysis using one machine-learning algorithm. My first test was to determine if there was a usable correlation between the date the state requested assistance from FEMA and the amount requested. I used a linear regression model and two FEMA mission assignment database values. 

After downloading the dataset, I used Microsoft Excel 2022 to review it. I opened the CSV in Excel, created a table from the data set, and saved it as an Excel workbook. I created a series of pivot tables to understand the data and requirements for data cleansing. I determined that there were only 29 rows without a ‘daterequested’ value, and the values for that field ran from February 1, 2012, to June 17, 2024, for a total of 29062 rows. The ‘requestedamount’ ran from 802,600,000.00 to -251747884.8, a survey of negative values representing a balancing operation against prior requests, called a de-obligation.

I decided to run the data as presented. I used Visual Studio Code to write Python code using pandas and Sklearn’s linear regression module. I wrote all the code in one Python file and will separate it into separate methods in subsequent weeks. 

Using pandas to load the CSV file into a data frame, I selected ‘date requested’ and ‘requested amount’ into a new data frame. I converted ‘date requested’ to a datetime value and ‘requested amount’ to a numeric datatype using pandas’ built-in functions  to_datetime and to_numeric, respectively. I created training and testing data frames by dividing the data set between rows before October 1, 2021, as training and after October 1, 2021, as testing. I then converted the datetime values in daterequested’ to floating point values using a lambda of the toordinal function. 

Converted both sets of values in training and testing frames to numpy arrays and fed them to an sklearn linear regression model. I predicted the values using the testing set dates and evaluated the results using the testing amounts. The results were a coefficient of 126.35659105, a mean squared error of 166401973390363.94, and a coefficient of determination of -0.00. The results shown in Figure 1 below indicate a low correlation between a given mission assignment's date and projected cost. I am considering running polynomial regression to increase the number of factors driving the regression along an axis. However, I determined it was beyond the project's scope, and the question was better asked using a more sophisticated algorithm. It is possible that the missing date or negative dollar amount values skewed the prediction, but I think it is more likely that the date and amount correlation occurs through other factors. I will explore this in the next phase when I train and test an ARIMA model.
